3. PreparaÃ§Ã£o e ExploraÃ§Ã£o dos Dados

3.1 Limpeza e Tratamento de Dados

ApÃ³s anÃ¡lise inicial, aplicou-se o seguinte pipeline de limpeza:

RemoÃ§Ã£o de colunas irrelevantes (Name, Location, Company, customerID, Onboard_date) para reduzir o ruÃ­do.

ConversÃ£o de variÃ¡veis temporais: Onboard_date foi transformada em Days_Onboard, representando o tempo desde a contrataÃ§Ã£o atÃ© uma data de referÃªncia (ex: 01/01/2017).

from datetime import datetime
df["Onboard_date"] = pd.to_datetime(df["Onboard_date"], format="%Y-%m-%d")
df["Days_Onboard"] = (pd.to_datetime("2017-01-01") - df["Onboard_date"]).dt.days
df = df.drop(columns=["Onboard_date"])

VerificaÃ§Ã£o de valores faltantes mostrou ausÃªncia significativa de dados ausentes, o que permitiu prosseguir sem imputaÃ§Ã£o.

3.2 Engenharia e CodificaÃ§Ã£o de VariÃ¡veis

Para preparar atributos categÃ³ricos para algoritmos de ML, foram aplicados:

One-hot encoding em Account_Manager, gerando colunas account_manager_0 e account_manager_1.

DiscretizaÃ§Ã£o do gasto total (Total_Purchase) em faixas (purchase_a, purchase_b, etc.):

df["purchase_range"] = pd.cut(df["Total_Purchase"], bins=4, labels=["a", "b", "c", "d"])
df = pd.get_dummies(df, columns=["purchase_range", "Account_Manager"], drop_first=True)

3.3 DivisÃ£o Treino/Teste e EstratÃ©gia de Balanceamento de Classes

Os dados foram divididos em treino (70%) e teste (30%), com estratificaÃ§Ã£o para preservar a proporÃ§Ã£o original de clientes que cancelaram. Em seguida, foi aplicada uma estratÃ©gia de balanceamento supervisionado no conjunto de treino.

Neste projeto, optou-se pelo uso de oversampling com a tÃ©cnica BorderlineSMOTE, que gera amostras sintÃ©ticas da classe minoritÃ¡ria (Churn = 1) em regiÃµes prÃ³ximas Ã  fronteira de decisÃ£o. Essa abordagem foi preferida em relaÃ§Ã£o ao undersampling, pois mantÃ©m todas as amostras da classe majoritÃ¡ria, evitando perda de informaÃ§Ã£o.

O uso do SMOTE contribuiu para a melhoria da capacidade preditiva do modelo ao expor o algoritmo a mais exemplos representativos da classe de interesse, o que Ã© especialmente importante em problemas desbalanceados como churn.

3.4 ConstruÃ§Ã£o do Pipeline de Modelagem

Foi montado um pipeline com FunctionTransformer, ColumnTransformer, e SMOTE, aplicado a trÃªs algoritmos:

Logistic Regression (penalizaÃ§Ã£o L1)

Random Forest

XGBoost (versÃ£o simplificada)

HiperparÃ¢metros foram ajustados com GridSearchCV, usando validaÃ§Ã£o cruzada estratificada (5 folds) e recall como mÃ©trica principal.

3.5 AvaliaÃ§Ã£o Comparativa dos Modelos e Justificativa da Escolha

Logistic Regression

Melhor resultado com C=10, penalty='l1', class_weight='balanced'

Recall mÃ©dio â‰ˆ 0.76, AUC = 0.842

Coeficientes esparsos e interpretÃ¡veis

Random Forest

Obteve desempenho superior no dataset desbalanceado, sem SMOTE

AUC â‰ˆ 0.83, recall levemente inferior apÃ³s balanceamento

Maior variabilidade entre folds

XGBoost

Performance bruta elevada

Maior sensibilidade a overfitting e necessidade de tunagem complexa

Menor adequaÃ§Ã£o ao contexto educacional

Justificativa final

A regressÃ£o logÃ­stica foi escolhida por apresentar:

Recall elevado com estabilidade

InterpretaÃ§Ã£o direta dos coeficientes

ImplementaÃ§Ã£o simples e reprodutÃ­vel

3.6 Escolha do Threshold Ideal

Por padrÃ£o, modelos classificam como positivo quando a probabilidade Ã© >0.5. Para maximizar recall, foi analisado o comportamento das mÃ©tricas em diferentes thresholds:

ðŸ“Œ Figura 5 â€“ Precision, Recall e F1-score vs Threshold


InterpretaÃ§Ã£o:

Recall aumenta conforme o threshold diminui

Precision e F1-score caem apÃ³s certo ponto

O threshold 0.24 foi escolhido por:

Maximizar recall sem comprometer drasticamente a precisÃ£o

Representar o ponto onde as mÃ©tricas comeÃ§am a divergir

Esse threshold passou a ser utilizado como ponto de decisÃ£o operacional, classificando como churn todos os clientes com probabilidade > 0.24.

